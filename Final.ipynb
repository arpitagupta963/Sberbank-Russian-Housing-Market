{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-SQu5oIcql3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from sklearn import preprocessing \n",
        "from sklearn.impute import KNNImputer\n",
        "import pickle\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import random\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPFRBHEAkSRd",
        "outputId": "357c3b7b-4bbb-4d03-9f5a-76cb1ea05517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kagglesdsdata/competitions/6392/44054/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1601614655&Signature=kdekCWtvrhiCUc3vLx%2Bu9CIHOP2uIvWVw%2FgVNcuHkjYRCsgKNQZmdPFSozQVeYkXkyrA83vk3JhgX5GilsU580rXcfDcgEkp5W%2BAAuouX5KSiHcGsSAr7pHpwQ0Qn1wNCnI4%2F9vrp7k7JpRMbh0PG%2Fj8miXWxfx6CMba0kgBXGjQGTSmU1SfMdzwyHJMrf7rpYOR8R5om5ycBcOsnG9k%2FfnHYCqE4CTanO%2BndjiHeGUYI3pAkdeB5Kw2kLq51cZd8N9NgZhXugcPkid1dmZ8ZTTUqsiZhRocc3NrwI90RABuEJmdcwyXchAtue%2FImDeb0kSxXwD7cSn70GGmP569yQ%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip\" -c -O 'train.csv.zip'\n",
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kagglesdsdata/competitions/6392/44054/test.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1601614691&Signature=DcNgCcbI9E0whdF4TwcffSDmaI3s1kTNU2dJy9qq3aVsxskb%2FjWXtMqd84pZZBU87vgm9cFTFtrfmSV8Zme3teJVEV9IF4dKs6EUBQklPqo37ZcTclO%2B6EI7oW9w5bAxuOF1Mnu3%2FDc%2Bd1XJBjADPYJun8uyAHhFXSuk7qC8ESk5rHEcw4c9VnVN2dWNAz8Nu6VMkvzvfFJVlRIVMAVPwzNErF5BkR2Pc%2BtTSw4cHNEsG5GiMevYZ9C%2FXq3YePn0lXDMlYfuJDLGoRg%2BOaapxqJWm1bGQ8L8Pkb3ZPY5Bi1kvL9NWS75fqMb7CZ4zsBZ38sTtTzV06xBf%2BPyG9mDBg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest.csv.zip\" -c -O 'test.csv.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-30 17:48:58--  https://storage.googleapis.com/kagglesdsdata/competitions/6392/44054/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1601614655&Signature=kdekCWtvrhiCUc3vLx%2Bu9CIHOP2uIvWVw%2FgVNcuHkjYRCsgKNQZmdPFSozQVeYkXkyrA83vk3JhgX5GilsU580rXcfDcgEkp5W%2BAAuouX5KSiHcGsSAr7pHpwQ0Qn1wNCnI4%2F9vrp7k7JpRMbh0PG%2Fj8miXWxfx6CMba0kgBXGjQGTSmU1SfMdzwyHJMrf7rpYOR8R5om5ycBcOsnG9k%2FfnHYCqE4CTanO%2BndjiHeGUYI3pAkdeB5Kw2kLq51cZd8N9NgZhXugcPkid1dmZ8ZTTUqsiZhRocc3NrwI90RABuEJmdcwyXchAtue%2FImDeb0kSxXwD7cSn70GGmP569yQ%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 142.250.107.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17919166 (17M) [application/zip]\n",
            "Saving to: ‘train.csv.zip’\n",
            "\n",
            "train.csv.zip       100%[===================>]  17.09M  32.8MB/s    in 0.5s    \n",
            "\n",
            "2020-09-30 17:48:59 (32.8 MB/s) - ‘train.csv.zip’ saved [17919166/17919166]\n",
            "\n",
            "--2020-09-30 17:48:59--  https://storage.googleapis.com/kagglesdsdata/competitions/6392/44054/test.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1601614691&Signature=DcNgCcbI9E0whdF4TwcffSDmaI3s1kTNU2dJy9qq3aVsxskb%2FjWXtMqd84pZZBU87vgm9cFTFtrfmSV8Zme3teJVEV9IF4dKs6EUBQklPqo37ZcTclO%2B6EI7oW9w5bAxuOF1Mnu3%2FDc%2Bd1XJBjADPYJun8uyAHhFXSuk7qC8ESk5rHEcw4c9VnVN2dWNAz8Nu6VMkvzvfFJVlRIVMAVPwzNErF5BkR2Pc%2BtTSw4cHNEsG5GiMevYZ9C%2FXq3YePn0lXDMlYfuJDLGoRg%2BOaapxqJWm1bGQ8L8Pkb3ZPY5Bi1kvL9NWS75fqMb7CZ4zsBZ38sTtTzV06xBf%2BPyG9mDBg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest.csv.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.195.128, 74.125.28.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4680015 (4.5M) [application/zip]\n",
            "Saving to: ‘test.csv.zip’\n",
            "\n",
            "test.csv.zip        100%[===================>]   4.46M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-09-30 17:49:00 (42.2 MB/s) - ‘test.csv.zip’ saved [4680015/4680015]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "226xp-dEtID2",
        "outputId": "a8b58bd7-6df2-43ad-86b6-1007becfd0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!unzip train.csv.zip\n",
        "!unzip test.csv.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._train.csv    \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: __MACOSX/._test.csv     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u3Ne_o7dLHz"
      },
      "source": [
        "def final_fun_1(X):\n",
        "\n",
        "  # Drop features that has little to no variance :\n",
        "\n",
        "  zero_variance = [\"culture_objects_top_25_raion\", \"oil_chemistry_raion\", \"railroad_terminal_raion\", \"nuclear_reactor_raion\",\n",
        "      \"build_count_foam\", \"big_road1_1line\", \"railroad_1line\", \"office_sqm_500\", \"trc_sqm_500\",\n",
        "      \"cafe_count_500_price_4000\", \"cafe_count_500_price_high\", \"mosque_count_500\", \"leisure_count_500\",\n",
        "      \"office_sqm_1000\", \"trc_sqm_1000\", \"cafe_count_1000_price_high\", \"mosque_count_1000\", \"cafe_count_1500_price_high\",\n",
        "      \"mosque_count_1500\", \"cafe_count_2000_price_high\"]\n",
        "  \n",
        "  useless_ids = [\"ID_metro\", \"ID_railroad_station_walk\", \"ID_railroad_station_avto\", \"ID_big_road1\", \"ID_big_road2\",\n",
        "      \"ID_railroad_terminal\", \"ID_bus_terminal\"]\n",
        "\n",
        "  X.drop(zero_variance + useless_ids, axis = 1, inplace = True)\n",
        "\n",
        "  # Replace Irrevant data from relevant one\n",
        "\n",
        "  # State\n",
        "  X.state.replace({33:3},inplace=True)\n",
        "\n",
        "  # Material\n",
        "  X['material'].replace(to_replace = 3, value = 1, inplace = True)\n",
        "\n",
        "  # full_sq\n",
        "  X['full_sq'].replace(to_replace = 0, value = np.nan, inplace = True)\n",
        "\n",
        "  # Max Floor\n",
        "  X['max_floor'].replace(to_replace = 0, value = np.nan, inplace = True)\n",
        "\n",
        "  # Number of Rooms\n",
        "  X['num_room'].replace(to_replace = 0, value = np.nan, inplace = True)\n",
        "\n",
        "  # Feature Engineering #\n",
        "\n",
        "  #print(\"Doing Feature Engineering \")\n",
        "\n",
        "  # Additional timestamp variables:\n",
        "  X['year'] = X['timestamp'].apply(lambda x: int(x[0:4]))\n",
        "  X['year_mo'] = X['timestamp'].apply(lambda x: x[0:7])\n",
        "\n",
        "\n",
        "  # Residential & kitchen area to total area ratio:\n",
        "  X['resident_to_total_ratio'] = X['life_sq']/X['full_sq']\n",
        "\n",
        "  # Average area per room:\n",
        "  X['avg_room_area'] = X['life_sq']/X['num_room']\n",
        "\n",
        "  # Extra area:\n",
        "  X['extra_area'] = X['full_sq'] - X['life_sq']\n",
        "  X['extra_area_ratio'] = X['extra_area']/X['full_sq']\n",
        "\n",
        "  # Percentage of population in labor force:\n",
        "  X['pct_labor_force'] = X['work_all']/X['raion_popul']\n",
        "\n",
        "  # Apartment floor relative to building height:\n",
        "  X['floor_rel_total'] = X['floor']/X['max_floor']\n",
        "\n",
        "\n",
        "  # Some additional binary variables:\n",
        "  X['metro_flag'] = np.where(X['raion_popul'] > 150000, 1, 0)\n",
        "  X['large_flag'] = np.where(X['max_floor'] >= 20, 1, 0)\n",
        "  X['small_flag'] = np.where(X['max_floor'] <= 20, 1, 0)\n",
        "\n",
        "  # Average building height for subarea:\n",
        "  sub_area_means = X.groupby('sub_area').agg({'max_floor':np.mean}).reset_index().rename(columns={'max_floor':'mean_bldg_height'})\n",
        "  X = pd.merge(X, sub_area_means, on = ['sub_area'], how = 'left')\n",
        "\n",
        "  # Sales by month:\n",
        "  n_sales_months = X.groupby('year_mo').size().reset_index().rename(columns={0:'n_sales_month'})\n",
        "  X = pd.merge(X, n_sales_months, on = ['year_mo'], how = 'left')\n",
        "\n",
        "  # Average distance to Kremlin by subarea:\n",
        "  dist_to_kremlin = X.groupby('sub_area').agg({'kremlin_km':np.nanmean}).reset_index().rename(columns={'kremlin_km':'subarea_dist_to_kremlin'})\n",
        "  X = pd.merge(X, dist_to_kremlin, on = ['sub_area'], how = 'left')\n",
        "\n",
        "  # Count NaNs per row:\n",
        "  X['count_nan_per_row'] = X.isnull().sum(axis = 1)\n",
        "\n",
        "  # Apartment name:\n",
        "  X['apt_name'] = X['sub_area'] + X['metro_km_avto'].astype(str).apply(lambda x: x[0:5])\n",
        "  X['apt_name_yrmo'] = X['apt_name'] + X['year_mo']\n",
        "\n",
        "  #***********Missing value Imputation Start ***************************************************\n",
        "\n",
        "  # Select all the columns having missing values less than equal to 30%\n",
        "  missing_values = ((X.isna().sum())/X.shape[0])*100\n",
        "  missing_values.sort_values(ascending=False,inplace = True)\n",
        "\n",
        "  missing_values[(missing_values>0) & (missing_values<=30)].index\n",
        "  values = {'prom_part_5000': X['prom_part_5000'].median(),\n",
        "        'floor': X['floor'].median(),\n",
        "        'railroad_station_walk_km': X['railroad_station_walk_km'].median(),\n",
        "        'metro_min_walk': X['metro_min_walk'].median(),\n",
        "        'metro_km_walk': X['metro_km_walk'].median(),\n",
        "        'railroad_station_walk_min': X['railroad_station_walk_min'].median(),\n",
        "        'product_type': X['product_type'].mode()[0],\n",
        "        'green_part_2000': X['green_part_2000'].median(),\n",
        "        'full_sq': X['full_sq'].median(),\n",
        "        'floor_rel_total': X['floor_rel_total'].median(),\n",
        "        'max_floor': X['max_floor'].median(),\n",
        "        'num_room': X['num_room'].median(),\n",
        "        'material': X['material'].median(),\n",
        "        'preschool_quota': X['preschool_quota'].median(),\n",
        "        'cafe_sum_1000_min_price_avg': X['cafe_sum_1000_min_price_avg'].median(),\n",
        "        'cafe_sum_1000_max_price_avg': X['cafe_sum_1000_max_price_avg'].median(),\n",
        "          'cafe_avg_price_1000': X['cafe_avg_price_1000'].median(),\n",
        "        'extra_area': X['extra_area'].median(),\n",
        "        'resident_to_total_ratio': X['resident_to_total_ratio'].median(),\n",
        "        'extra_area_ratio': X['extra_area_ratio'].median(),\n",
        "          'life_sq': X['life_sq'].median(),\n",
        "          'build_count_before_1920': X['build_count_before_1920'].median(),\n",
        "          'build_count_brick': X['build_count_brick'].median(),\n",
        "          'build_count_1946-1970': X['build_count_1946-1970'].median(),\n",
        "          'raion_build_count_with_builddate_info': X['raion_build_count_with_builddate_info'].median(),  \n",
        "        'build_count_monolith': X['build_count_monolith'].median(),\n",
        "        'raion_build_count_with_material_info': X['raion_build_count_with_material_info'].median(),\n",
        "        'cafe_avg_price_1500': X['cafe_avg_price_1500'].median(),\n",
        "        'cafe_sum_1500_min_price_avg': X['cafe_sum_1500_min_price_avg'].median(),\n",
        "        'cafe_sum_1500_max_price_avg': X['cafe_sum_1500_max_price_avg'].median(),\n",
        "        'cafe_avg_price_2000': X['cafe_avg_price_2000'].median(),\n",
        "        'cafe_sum_2000_min_price_avg': X['cafe_sum_2000_min_price_avg'].median(),\n",
        "        'cafe_sum_2000_max_price_avg': X['cafe_sum_2000_max_price_avg'].median()\n",
        "        }\n",
        "\n",
        "                      \n",
        "  X.fillna(value=values,inplace=True)\n",
        "\n",
        "  # Select all the columns having missing values between 5 to 30%\n",
        "  missing_values[(missing_values>30)].index\n",
        "\n",
        "  knn_model = pickle.load(open(\"model_var_knn.pkl\", 'rb'))\n",
        "\n",
        "  col = ['hospital_beds_raion','avg_room_area','state']\n",
        "\n",
        "  for i in col:\n",
        "      X[i] = knn_model[i].transform(X[[i]])\n",
        "\n",
        "\n",
        "  test_id = X['id']\n",
        "  X.drop(['id','timestamp'],axis=1,inplace=True)\n",
        "\n",
        "  lis_of_all_models, reg, cat_dict = pickle.load(open(\"model_var.pkl\", 'rb'))\n",
        "\n",
        "\n",
        "  for cat in cat_dict.keys():\n",
        "    X[cat] = X[cat].map(lambda s: '<unknown>' if s not in cat_dict[cat].classes_ else s)\n",
        "    X[cat] = cat_dict[cat].transform(X[cat])\n",
        "\n",
        "  test_pred = list()\n",
        "\n",
        "  for model in lis_of_all_models:\n",
        "    test_pred.append(model.predict(X.values))\n",
        "\n",
        "  test_pred = np.array(test_pred)\n",
        "  test_pred = test_pred.T\n",
        "\n",
        "  pred = reg.predict(test_pred)\n",
        "  X['price_doc'] = np.expm1(pred)\n",
        "  X['id'] = test_id\n",
        "  return X[['id','price_doc']]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2bAW-XDvaSR"
      },
      "source": [
        "def final_fun_2(X,Y):\n",
        "\n",
        "  y_pred = final_fun_1(X)['price_doc']\n",
        "  return mean_squared_log_error(y_pred, Y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzOWXLQg1FEH"
      },
      "source": [
        "# Testing the 1st Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUUEzhME1JQ9",
        "outputId": "3bfe7f6f-d9c0-4204-acea-41601a7161e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X = pd.read_csv('test.csv')\n",
        "df = final_fun_1(X)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>price_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30474</td>\n",
              "      <td>5.548860e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30475</td>\n",
              "      <td>8.202937e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30476</td>\n",
              "      <td>4.882520e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30477</td>\n",
              "      <td>5.514335e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30478</td>\n",
              "      <td>5.121881e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id     price_doc\n",
              "0  30474  5.548860e+06\n",
              "1  30475  8.202937e+06\n",
              "2  30476  4.882520e+06\n",
              "3  30477  5.514335e+06\n",
              "4  30478  5.121881e+06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaP-hQLP1KoG"
      },
      "source": [
        "# Testing the 2nd Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PLEUhPM1N-5",
        "outputId": "21772795-37eb-41d5-ef33-c28b5d4170e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = pd.read_csv('train.csv')\n",
        "Y = X['price_doc']\n",
        "X.drop(['price_doc'],axis=1,inplace=True)\n",
        "\n",
        "print(final_fun_2(X,Y))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1774656984352424\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}